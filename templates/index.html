<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Live Browser Speech-to-Text Multi-Field (Auto-Focus)</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <style>
    /* Core Styles */
    body { background: #f4f7f9; font-family: 'Inter', sans-serif; padding-top: 4rem; }
    .mic-button { transition: .2s; background: linear-gradient(145deg,#6b21a8,#8b5cf6); box-shadow: 0 4px 15px rgba(0,0,0,.15); width:50px;height:50px;border-radius:9999px;display:flex;align-items:center;justify-content:center;color:white;cursor:pointer;flex-shrink:0; }
    .mic-button.small-mic { width: 40px; height: 40px; }
    .mic-button:hover:not(.listening):not([disabled]) { transform: scale(1.08); }
    .mic-button[disabled] { cursor:not-allowed; opacity:.5; background:#ccc; box-shadow:none; }
    .listening { animation: pulse 1.4s infinite; background: linear-gradient(145deg,#dc2626,#ef4444) !important; box-shadow:0 0 0 0 rgba(220,38,38,.7); }
    @keyframes pulse { 0%{transform:scale(1)}70%{transform:scale(1.08)}100%{transform:scale(1)} }

    /* Custom Bar Styles */
    .text-input-bar {
      background:#fff;
      padding:8px 12px;
      border-radius:4px;
      font-size:16px;
      border:1px solid #ccc;
      color:#777;
      width:100%;
      min-height:40px;
      display:flex;
      align-items:center;
      justify-content:flex-start;
      box-shadow:inset 0 1px 3px rgba(0,0,0,.05);
      flex-grow:1;
      text-align: left;
      cursor:text;
      white-space: pre-wrap; /* keep newlines visible */
    }
    .live-text { color:#1f2937; font-weight:500; }
    .multi-line-box {
      min-height: 100px;
      align-items: flex-start;
      padding-top: 12px;
    }

    /* Parameter field focus style */
    .parameter-field.active-field {
      border-color: #8b5cf6;
      box-shadow: 0 0 0 2px rgba(139, 92, 246, 0.2);
    }

    .sr-only { position: absolute !important; width:1px;height:1px;padding:0;margin:-1px;overflow:hidden;clip:rect(0,0,0,0);white-space:nowrap;border:0; }
  </style>
</head>
<body class="p-6 min-h-screen flex items-start justify-center">
  <div class="max-w-4xl w-full mx-auto space-y-6 bg-white p-8 rounded-2xl shadow-2xl text-center">
    <h1 class="text-3xl font-extrabold text-gray-800 mb-2">Voice Support</h1>

    <section id="speak-to-type-section" class="space-y-4" aria-labelledby="speak-to-type-heading">
      <div class="flex items-start gap-4">
        <h2 id="speak-to-type-heading" class="text-lg font-bold text-gray-700 whitespace-nowrap pt-1">Speak to Type:</h2>
        <div class="relative w-full flex flex-col">
          <div class="flex gap-4">
            <button id="mic-button-1" class="mic-button small-mic mt-1" onclick="toggleRecording(1)" aria-pressed="false" aria-label="Toggle microphone for Speak to Type">
              <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M12 2a3 3 0 0 0-3 3v7a3 3 0 0 0 6 0V5a3 3 0 0 0-3-3Z"/><path d="M19 10v2a7 7 0 0 1-14 0v-2"/><line x1="12" y1="19" x2="12" y2="22"/></svg>
            </button>
            <div id="transcription-bar-1" class="text-input-bar multi-line-box" role="textbox" aria-multiline="true" tabindex="0">Click the mic button next to the text to start speaking...</div>
          </div>

          <div class="text-left text-xs text-gray-700 mt-2 px-3 py-2 border border-gray-300 rounded bg-gray-50">
            **Commands**: Speak "Next Line" for a line break.
            <div class="mt-1">
              **Punctuation Commands (Speak to insert)**:
              <ul class="list-disc pl-5 mt-1 grid grid-cols-2 gap-x-4">
                <li>Speak **"full stop"** or **"dot"** (.)</li>
                <li>Speak **"comma"** (,)</li>
                <li>Speak **"question mark"** (?)</li>
                <li>Speak **"exclamation mark"** (!)</li>
                <li>Speak **"semicolon"** (;)</li>
                <li>Speak **"dash"** or **"hyphen"** (-)</li>
                <li>Speak **"slash"** (/) </li>
              </ul>
            </div>
          </div>
                    <button id="clear-btn-1" class="self-end mt-1 mr-1 text-sm text-gray-400 hover:text-gray-700 font-semibold" onclick="clearText(1)">Clear Text</button>
        </div>
      </div>
    </section>

    <hr class="my-6 border-t-2 border-gray-300">

    <div class="flex justify-center py-4">
      <button id="master-mic-button" class="mic-button" onclick="toggleMasterRecording()" aria-pressed="false" aria-label="Toggle master microphone">
        <svg xmlns="http://www.w3.org/2000/svg" width="28" height="28" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M12 2a3 3 0 0 0-3 3v7a3 3 0 0 0 6 0V5a3 3 0 0 0-3-3Z"/><path d="M19 10v2a7 7 0 0 1-14 0v-2"/><line x1="12" y1="19" x2="12" y2="22"/></svg>
      </button>
    </div>

    <section id="parameters-section" class="space-y-4 pt-4" aria-labelledby="parameters-heading">
      <h2 id="parameters-heading" class="sr-only">Parameters (controlled by master mic)</h2>

      <!-- Parameter Fields 1..5 displayed as transcription-bar-2..6 -->
      <div class="flex items-center gap-4">
        <h3 class="text-lg font-medium text-left text-gray-700 w-1/4 flex-shrink-0">Parameter 1</h3>
        <div class="relative w-full flex-grow">
          <div id="transcription-bar-2" class="text-input-bar parameter-field" onclick="setActiveField(2)" role="textbox" tabindex="0">Click to focus/edit...</div>
          <button id="clear-btn-2" class="absolute right-3 top-1/2 -translate-y-1/2 text-gray-400 hover:text-gray-700 text-xl" onclick="clearText(2)" aria-label="Clear Parameter 1">‚úï</button>
        </div>
      </div>

      <div class="flex items-center gap-4">
        <h3 class="text-lg font-medium text-left text-gray-700 w-1/4 flex-shrink-0">Parameter 2</h3>
        <div class="relative w-full flex-grow">
          <div id="transcription-bar-3" class="text-input-bar parameter-field" onclick="setActiveField(3)" role="textbox" tabindex="0">Click to focus/edit...</div>
          <button id="clear-btn-3" class="absolute right-3 top-1/2 -translate-y-1/2 text-gray-400 hover:text-gray-700 text-xl" onclick="clearText(3)" aria-label="Clear Parameter 2">‚úï</button>
        </div>
      </div>

      <div class="flex items-center gap-4">
        <h3 class="text-lg font-medium text-left text-gray-700 w-1/4 flex-shrink-0">Parameter 3</h3>
        <div class="relative w-full flex-grow">
          <div id="transcription-bar-4" class="text-input-bar parameter-field" onclick="setActiveField(4)" role="textbox" tabindex="0">Click to focus/edit...</div>
          <button id="clear-btn-4" class="absolute right-3 top-1/2 -translate-y-1/2 text-gray-400 hover:text-gray-700 text-xl" onclick="clearText(4)" aria-label="Clear Parameter 3">‚úï</button>
        </div>
      </div>

      <div class="flex items-center gap-4">
        <h3 class="text-lg font-medium text-left text-gray-700 w-1/4 flex-shrink-0">Parameter 4</h3>
        <div class="relative w-full flex-grow">
          <div id="transcription-bar-5" class="text-input-bar parameter-field" onclick="setActiveField(5)" role="textbox" tabindex="0">Click to focus/edit...</div>
          <button id="clear-btn-5" class="absolute right-3 top-1/2 -translate-y-1/2 text-gray-400 hover:text-gray-700 text-xl" onclick="clearText(5)" aria-label="Clear Parameter 4">‚úï</button>
        </div>
      </div>

      <div class="flex items-center gap-4">
        <h3 class="text-lg font-medium text-left text-gray-700 w-1/4 flex-shrink-0">Parameter 5</h3>
        <div class="relative w-full flex-grow">
          <div id="transcription-bar-6" class="text-input-bar parameter-field" onclick="setActiveField(6)" role="textbox" tabindex="0">Click to focus/edit...</div>
          <button id="clear-btn-6" class="absolute right-3 top-1/2 -translate-y-1/2 text-gray-400 hover:text-gray-700 text-xl" onclick="clearText(6)" aria-label="Clear Parameter 5">‚úï</button>
        </div>
      </div>

    </section>

    <div class="text-center pt-4">
      <p id="status-message" class="text-sm text-gray-600 font-semibold"></p>
    </div>
  </div>

<script>
/*
  Behavior summary:
  - Field 1 (transcription-bar-1) has its own mic button.
  - Fields 2..6 are controlled by the central/master mic.
  - Active field is highlighted. Speaking stores into finalTranscripts[field].
  - Commands:
      * For field 1: "next line", "new line", "carriage return" -> insert newline
      * For fields 2..5: "next", "move to next", "next field", "field next" -> finalize and move to next field
  - Silence auto-stops recognition after SILENCE_TIMEOUT_MS.
  - final text is auto-punctuated and numbers converted for simple cases.
*/

let recognizer = null;
let isListening = false;
let silenceTimer = null;
const SILENCE_TIMEOUT_MS = 5000; // 5s silence -> auto-stop

const totalFields = 6;
const finalTranscripts = {1: '', 2: '', 3: '', 4: '', 5: '', 6: ''};
let currentSpeechText = '';
let activeField = 2; // default focus is first parameter field (controlled by master mic)

const STATUS_MSG_DEFAULT = "Click the central mic to start recording on Parameter 1, or click the mic next to 'Speak to Type'.";
const NEXT_COMMANDS = ["next","move to next", "next field", "field next"];
const NEXT_LINE_COMMANDS = ["next line", "new line", "carriage return"];

function getElements(fieldNum) {
  return {
    micButton: fieldNum === 1 ? document.getElementById('mic-button-1') : document.getElementById('master-mic-button'),
    transBar: document.getElementById(`transcription-bar-${fieldNum}`),
  };
}

const statusMsg = document.getElementById('status-message');

function autoPunctuate(text) {
  let result = text;
  result = result.replace(/\bcomma\b/gi, ", ");
  result = result.replace(/\bkama\b/gi, ", ");
  result = result.replace(/\bfull stop\b/gi, ". ");
  result = result.replace(/\bpoint\b/gi, ". ");
  result = result.replace(/\bdot\b/gi, ". ");
  result = result.replace(/\bslash\b/gi, "/");
  result = result.replace(/\bbackward slash\b/gi, "\\");
  result = result.replace(/\bcolum\b/gi, ":");
  result = result.replace(/\bcolon\b/gi, ":");
  result = result.replace(/\bsemicolon\b/gi, ";");
  result = result.replace(/\bSemi colon\b/gi, ";");
  result = result.replace(/\bdash\b/gi, "-");
  result = result.replace(/\bhyphen\b/gi, "-");
  result = result.replace(/\bquestion mark\b/gi, "?");
  result = result.replace(/\bexclamation mark\b/gi, "!");
  
  //result = result.replace(/([.,:;?!])(\S)/g, '$1 $2');
  result = result.replace(/(\.|\,){2,}/g, '$1');
  //result = result.replace(/, ,/g, ", ");
  //result = result.replace(/,,/g, ",");
  //result = result.replace(/\. \./g, ".");
  //result = result.replace(/\.\./g, ".");
  result = result.replace(/ {2,}/g, " ");
  return result.trim();
}

function convertWordsToNumbers(text) {
  let result = text;
  const numWords = {
    'zero': '0', 'one': '1', 'two': '2', 'three': '3', 'four': '4', 'five': '5',
    'six': '6', 'seven': '7', 'eight': '8', 'nine': '9', 'oh': '0',
  };
  for (const word in numWords) {
    const regex = new RegExp(`\\b${word}\\b`, 'gi');
    result = result.replace(regex, numWords[word]);
  }
  // Simple expansions
  result = result.replace(/\b1\s+hundred\b/gi, '100');
  result = result.replace(/\b1\s+thousand\b/gi, '1000');
  result = result.replace(/\b1\s+million\b/gi, '1000000');
  result = result.replace(/\bhundred\b/gi, '100');
  result = result.replace(/\bthousand\b/gi, '1000');
  return result.trim();
}

function updateFieldState(fieldNum, isEnabled, isCurrent) {
  const { transBar } = getElements(fieldNum);

  document.querySelectorAll('.parameter-field').forEach(el => el.classList.remove('active-field'));
  if (isCurrent && fieldNum >= 2) {
    transBar.classList.add('active-field');
  }

  const currentText = finalTranscripts[fieldNum];
  if (currentText) {
    transBar.textContent = currentText;
    transBar.classList.add('live-text');
  } else if (isCurrent && !isListening) {
    const defaultText = (fieldNum === 1) ? "Start speaking now for the multiline text..." : "Start speaking and when done say 'Next' to move onto the next parameter2.";
    transBar.textContent = defaultText;
    transBar.classList.remove('live-text');
  } else if (!isCurrent && !isListening) {
    const defaultText = (fieldNum === 1) ? "Click the mic button next to the text to start speaking..." : "Click to focus/edit...";
    transBar.textContent = defaultText;
    transBar.classList.remove('live-text');
  }
}

function initializeSpeechRecognition() {
  const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
  if (!SR) {
    document.getElementById('transcription-bar-1').textContent = "Error: Web Speech Recognition API not supported in this browser.";
    document.getElementById('mic-button-1').disabled = true;
    document.getElementById('master-mic-button').disabled = true;
    statusMsg.textContent = "Please use Chrome or Edge for this feature.";
    return null;
  }

  recognizer = new SR();
  recognizer.continuous = true;
  recognizer.interimResults = true;
  recognizer.lang = "en-US"; // Set desired language

  for (let i = 1; i <= totalFields; i++) {
    updateFieldState(i, true, i === activeField);
  }
  statusMsg.textContent = STATUS_MSG_DEFAULT;

  recognizer.onresult = (e) => {
    
    clearTimeout(silenceTimer);
    silenceTimer = setTimeout(() => {
      if (isListening) recognizer.stop();
    }, SILENCE_TIMEOUT_MS);

    let interimTranscript = '';
    let finalTranscriptSegment = '';

    for (let i = e.resultIndex; i < e.results.length; i++) {
      let transcript = e.results[i][0].transcript;
      transcript = transcript.replace(/[.,!?:;]$/, '').trim();
      if (e.results[i].isFinal) {
        finalTranscriptSegment += transcript + ' ';
        //finalTranscriptSegment = finalTranscriptSegment.replace(/[.,!?:;]$/, '').trim() + ' ';
      } else {
        interimTranscript += transcript+ ' ';
      }
    }

    // Newline handling for field 1
    if (activeField === 1 && finalTranscriptSegment) {
      NEXT_LINE_COMMANDS.forEach(cmd => {
        const regex = new RegExp(`\\b${cmd}\\b`, 'gi');
        if (regex.test(finalTranscriptSegment)) {
          finalTranscriptSegment = finalTranscriptSegment.replace(regex, '').trim();
          finalTranscriptSegment += '\n';
        }
      });
    }

    // NEXT command for parameter fields (2..5)
    if (activeField > 1 && activeField < totalFields && finalTranscriptSegment) {
      let commandFound = false;
      NEXT_COMMANDS.forEach(cmd => {
        if (new RegExp(`\\b${cmd}\\b`, 'gi').test(finalTranscriptSegment)) {
          commandFound = true;
        }
      });

      if (commandFound) {
        // Capture the final text before stopping
        currentSpeechText += finalTranscriptSegment;
        recognizer.stop(); // onend will handle moving to next field
        return;
      }
    }

    currentSpeechText += finalTranscriptSegment;

    const prefix = finalTranscripts[activeField].trim();
    const currentSessionText = (currentSpeechText + ' ' + interimTranscript).trim();
    const fullTranscript = prefix ? `${prefix} ${currentSessionText}` : currentSessionText;

    if (fullTranscript) {
      let displayTranscript = autoPunctuate(fullTranscript);
      getElements(activeField).transBar.textContent = displayTranscript;
      getElements(activeField).transBar.classList.add('live-text');
    }
  };

  recognizer.onend = () => {
    isListening = false;
    getElements(activeField).micButton.classList.remove("listening");
    clearTimeout(silenceTimer);

    let newFinalText = currentSpeechText.trim();
    let containsNextCommand = false;

    if (activeField > 1 && activeField < totalFields) {
      NEXT_COMMANDS.forEach(cmd => {
        const regex = new RegExp(`\\b${cmd}\\b`, 'gi');
        if (regex.test(newFinalText)) {
          containsNextCommand = true;
          newFinalText = newFinalText.replace(regex, '').trim();
        }
      });
    }

    let finalQuery = (finalTranscripts[activeField] + ' ' + newFinalText).trim();
    //finalQuery = convertWordsToNumbers(finalQuery);
    finalQuery = autoPunctuate(finalQuery).trim();
    finalQuery = autoPunctuate(convertWordsToNumbers(finalQuery)).trim();
    const trailingPunctuationRegex = /[.,;!]$/;
    while (trailingPunctuationRegex.test(finalQuery)){
      finalQuery = finalQuery.substring(0, finalQuery.length - 1).trim();
    }
    //if (activeField === 1){
      //const punctuationRegex = /[.,!?:;]$/i;
      //if (finalQuery.trim().length > 0 && !punctuationRegex.test(finalQuery)){
        //finalQuery = finalQuery + '.';
      //}
    //}else{
      //const trailingPunctuationRegex = /[.,!?:;]$/;
      //if (trailingPunctuationRegex.test(finalQuery)){
        //finalQuery = finalQuery.substring(0, finalQuery.length - 1);
      //}
    //}

    //if (finalQuery.endsWith('.')) {
      //finalQuery = finalQuery.substring(0, finalQuery.length - 1);
    //}

    currentSpeechText = '';
    finalTranscripts[activeField] = finalQuery;

    // update UI
    updateFieldState(activeField, true, activeField === activeField);
    if (finalQuery) {
      statusMsg.textContent = `Field ${activeField} complete. Final text saved.`;
    } else {
      statusMsg.textContent = `No new speech detected for Field ${activeField}. Tap mic to speak.`;
    }

    sendToServer(activeField, finalQuery);

    if (containsNextCommand) {
      handleNextField();
    } else if (activeField === totalFields) {
      statusMsg.textContent = "‚úÖ Last parameter field complete. You can click any mic or text box to edit a field.";
    }
  };

  recognizer.onerror = (e) => {
    isListening = false;
    getElements(activeField).micButton.classList.remove("listening");
    clearTimeout(silenceTimer);
    statusMsg.textContent = `‚ö†Ô∏è Error in Field ${activeField}: ${e.error}. Try granting microphone access and refreshing.`;
    console.error("Speech Recognition Error:", e.error);
    updateFieldState(activeField, true, activeField === activeField);
    currentSpeechText = '';
  };

  return recognizer;
}

function handleNextField() {
  if (activeField < totalFields) {
    updateFieldState(activeField, true, false);
    activeField += 1;
    updateFieldState(activeField, true, true);
    statusMsg.textContent = `‚û°Ô∏è Moved to Field ${activeField}. Mic automatically activated.`;
    // Auto-start the new field using the master mic
    setTimeout(() => startRecording(activeField), 120);
  } else {
    statusMsg.textContent = "‚úÖ All parameter fields complete! Click any mic or text box to switch fields.";
  }
}

window.setActiveField = function(fieldNum) {
  if (isListening) {
    recognizer.stop();
  }
  updateFieldState(activeField, true, false);
  activeField = fieldNum;
  updateFieldState(activeField, true, true);
  const micType = (fieldNum === 1) ? 'its dedicated mic' : 'the central mic';
  statusMsg.textContent = `Focus switched to Field ${fieldNum}. Click ${micType} to start recording.`;
}

// Field 1 dedicated mic toggler
window.toggleRecording = function(fieldNum) {
  if (fieldNum !== 1) return;
  if (!recognizer || getElements(fieldNum).micButton.disabled) return;
  if (isListening) {
    if (fieldNum === activeField) {
      recognizer.stop();
      return;
    } else {
      recognizer.stop();
      setTimeout(() => startRecording(fieldNum), 120);
      return;
    }
  }
  startRecording(fieldNum);
};

// Master mic (controls fields 2..6)
window.toggleMasterRecording = function() {
  if (activeField === 1) {
    setActiveField(2);
  }
  if (!recognizer || getElements(activeField).micButton.disabled) return;
  if (isListening) {
    recognizer.stop();
    return;
  }
  startRecording(activeField);
};

function startRecording(fieldNum) {
  try {
    if (!recognizer) return;
    if (fieldNum !== activeField) setActiveField(fieldNum);
    recognizer.continuous = true;
    currentSpeechText = '';
    const { micButton, transBar } = getElements(activeField);
    const previousText = finalTranscripts[activeField].trim();
    transBar.textContent = previousText ? `${previousText} Listening...` : "Listening...";
    transBar.classList.add('live-text');
    recognizer.start();
    isListening = true;
    micButton.classList.add("listening");

    clearTimeout(silenceTimer);
    silenceTimer = setTimeout(() => {
      if (isListening) recognizer.stop();
    }, SILENCE_TIMEOUT_MS);

    let commandHint;
    if (activeField === 1) {
      commandHint = `. This field allows up to ${SILENCE_TIMEOUT_MS/1000} seconds of silence. Say 'Next line' to insert a line break.`;
    } else if (activeField < totalFields) {
      commandHint = `. Say 'Move to next' or 'Next' to jump to Parameter ${activeField + 1}. Allows ${SILENCE_TIMEOUT_MS/1000}s silence.`;
    } else {
      commandHint = `. Final parameter field. Allows ${SILENCE_TIMEOUT_MS/1000}s silence.`;
    }
    statusMsg.textContent = `üé§ Field ${activeField}: Speak now...${commandHint}`;
  } catch (e) {
    console.error("Start error:", e);
    statusMsg.textContent = `‚ö†Ô∏è Error starting mic for Field ${activeField}. Check permissions or refresh.`;
  }
}

window.clearText = function(fieldNum) {
  if (isListening && fieldNum === activeField) {
    recognizer.stop();
  }
  finalTranscripts[fieldNum] = '';
  currentSpeechText = '';
  updateFieldState(fieldNum, true, fieldNum === activeField);
  statusMsg.textContent = `Text for Field ${fieldNum} cleared.`;
  sendToServer(fieldNum, '');
};

function sendToServer(field, text) {
  // Replace with actual server call when ready.
  const dataToSend ={
    field: field,
    text: text
  };
  fetch('/save_transcript', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json'
    },
    body: JSON.stringify(dataToSend)
  })
  .then(response => response.json())
  .then(data => {
    if (data.success) {
      console.log(`[Server] Field ${field} saved successfully.`);
    } else {
      console.error(`[Server Error] Failed to save field ${field}:`, data.message);
    }
  })
  .catch((error) => {
    console.error('[Fetch Error]: Could not reach server to save transcript.', error);
  });
  console.log(`[Simulated Server Call] Field: ${field}, Text: "${text}"`);
}

// Initialize on load
initializeSpeechRecognition();
</script>
</body>
</html>
