<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Live Browser Speech-to-Text - Speak to Type</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <style>
    /* Core Styles */
    body { background: #f4f7f9; font-family: 'Inter', sans-serif; padding-top: 4rem; }
    .mic-button { transition: .2s; background: linear-gradient(145deg,#6b21a8,#8b5cf6); box-shadow: 0 4px 15px rgba(0,0,0,.15); width:50px;height:50px;border-radius:9999px;display:flex;align-items:center;justify-content:center;color:white;cursor:pointer;flex-shrink:0; }
    .mic-button.small-mic { width: 40px; height: 40px; }
    .mic-button:hover:not(.listening):not([disabled]) { transform: scale(1.08); }
    .mic-button[disabled] { cursor:not-allowed; opacity:.5; background:#ccc; box-shadow:none; }
    .listening { animation: pulse 1.4s infinite; background: linear-gradient(145deg,#dc2626,#ef4444) !important; box-shadow:0 0 0 0 rgba(220,38,38,.7); }
    @keyframes pulse { 0%{transform:scale(1)}70%{transform:scale(1.08)}100%{transform:scale(1)} }

    /* Custom Bar Styles */
    .text-input-bar {
      background:#fff;
      padding:8px 12px;
      border-radius:4px;
      font-size:16px;
      border:1px solid #ccc;
      color:#777;
      width:100%;
      min-height:40px;
      display:flex;
      align-items:center;
      justify-content:flex-start;
      box-shadow:inset 0 1px 3px rgba(0,0,0,.05);
      flex-grow:1;
      text-align: left;
      cursor:text;
      white-space: pre-wrap; /* keep newlines visible */
    }
    .live-text { color:#1f2937; font-weight:500; }
    .multi-line-box {
      min-height: 120px;
      align-items: flex-start;
      padding-top: 12px;
    }
    /* New style for requested instruction format */
    .instruction-list {
        font-family: monospace;
        white-space: pre;
        line-height: 1.5;
        text-align: left;
        padding-left: 20px;
        color: #4b5563; /* text-gray-700 */
    }
  </style>
</head>
<body class="p-6 min-h-screen flex items-start justify-center">
  <div class="max-w-4xl w-full mx-auto space-y-6 bg-white p-8 rounded-2xl shadow-2xl text-center">
    <h1 class="text-3xl font-extrabold text-gray-800 mb-2">Speak to Type Field</h1>

    <section id="speak-to-type-section" class="space-y-4" aria-labelledby="speak-to-type-heading">
      <div class="flex items-start gap-4">
        <h2 id="speak-to-type-heading" class="text-lg font-bold text-gray-700 whitespace-nowrap pt-1">Transcription:</h2>
        <div class="relative w-full flex flex-col">
          <div class="flex gap-4">
            <button id="mic-button-1" class="mic-button small-mic mt-1" onclick="toggleRecording(1)" aria-pressed="false" aria-label="Toggle microphone for Speak to Type">
              <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M12 2a3 3 0 0 0-3 3v7a3 3 0 0 0 6 0V5a3 3 0 0 0-3-3Z"/><path d="M19 10v2a7 7 0 0 1-14 0v-2"/><line x1="12" y1="19" x2="12" y2="22"/></svg>
            </button>
            <div id="transcription-bar-1" class="text-input-bar multi-line-box" role="textbox" aria-multiline="true" tabindex="0">Click the mic button to start speaking...</div>
          </div>

          <button id="clear-btn-1" class="self-end mt-2 text-sm text-gray-400 hover:text-gray-700 font-semibold" onclick="clearText(1)">Clear Text</button>
          
          <div class="text-left text-xs text-gray-700 mt-4 p-3 border border-gray-300 rounded bg-gray-50">
            <p class="font-bold mb-1">To start typing on next Line speak "Next Line".</p>
            <p class="mb-1">When you speak either of the following it will be replaced by its actual representation :</p>
            <div class="instruction-list">
                comma              ,
                colon              :
                Hyphen/dash        -
                semicolon          ;
                slash              /
                backward slash     \\
                question mark      ?
                FullStop/dot/point  .
                Exclamation Mark    !
            </div>
          </div>
        </div>
      </div>
    </section>
    
    <div class="text-center pt-4">
      <p id="status-message" class="text-sm text-gray-600 font-semibold"></p>
    </div>
  </div>

<script>
let recognizer = null;
let isListening = false;
// Removed silenceTimer and SILENCE_TIMEOUT_MS

const activeField = 1; // Fixed field for this app
const finalTranscripts = {1: ''};
let currentSpeechText = '';

const STATUS_MSG_DEFAULT = "Click the mic button to start speaking..";
const NEXT_LINE_COMMANDS = ["next line", "new line", "carriage return"];

function getElements(fieldNum) {
  return {
    micButton: document.getElementById('mic-button-1'),
    transBar: document.getElementById(`transcription-bar-1`),
  };
}

const statusMsg = document.getElementById('status-message');

function autoPunctuate(text) {
  let result = text;
  result = result.replace(/\bcomma\b/gi, ", ");
  result = result.replace(/\b(comma | kama)\b/gi, ", ");
  //result = result.replace(/\bkama\b/gi, ",");
  result = result.replace(/\bfull stop\b/gi, ".");
  result = result.replace(/\bpoint\b/gi, ".");
  result = result.replace(/\bdot\b/gi, ".");
  result = result.replace(/\bslash\b/gi, "/");
  result = result.replace(/\bbackward slash\b/gi, "\\");
  result = result.replace(/\bcolon\b/gi, ":");
  result = result.replace(/\bcolum\b/gi, ":");
  result = result.replace(/\bsemicolon\b/gi, ";");
  result = result.replace(/\bSemi colon\b/gi, ";");
  result = result.replace(/\bdash\b/gi, "-");
  result = result.replace(/\bhyphen\b/gi, "-");
  result = result.replace(/\bquestion mark\b/gi, "?");
  result = result.replace(/\bexclamation mark\b/gi, "!");
  result = result.replace(/(\.|\,){2,}/g, '$1');
  result = result.replace(/ {2,}/g, " ");
  return result.trim();
}

function convertWordsToNumbers(text) {
  let result = text;
  const numWords = {
    'zero': '0', 'one': '1', 'two': '2', 'three': '3', 'four': '4', 'five': '5',
    'six': '6', 'seven': '7', 'eight': '8', 'nine': '9', 'oh': '0',
  };
  for (const word in numWords) {
    const regex = new RegExp(`\\b${word}\\b`, 'gi');
    result = result.replace(regex, numWords[word]);
  }
  result = result.replace(/\b1\s+hundred\b/gi, '100');
  result = result.replace(/\b1\s+thousand\b/gi, '1000');
  result = result.replace(/\b1\s+million\b/gi, '1000000');
  result = result.replace(/\bhundred\b/gi, '100');
  result = result.replace(/\bthousand\b/gi, '1000');
  return result.trim();
}

function updateFieldState() {
  const { transBar } = getElements(activeField);
  const currentText = finalTranscripts[activeField];
  if (currentText) {
    transBar.textContent = currentText;
    transBar.classList.add('live-text');
  } else if (!isListening) {
    transBar.textContent = "Click the mic button to start speaking...";
    transBar.classList.remove('live-text');
  }
}

function initializeSpeechRecognition() {
  const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
  if (!SR) {
    document.getElementById('transcription-bar-1').textContent = "Error: Web Speech Recognition API not supported in this browser.";
    document.getElementById('mic-button-1').disabled = true;
    statusMsg.textContent = "Please use Chrome or Edge for this feature.";
    return null;
  }

  recognizer = new SR();
  recognizer.continuous = true; // Essential for continuous listening
  recognizer.interimResults = true;
  recognizer.lang = "en-US";

  updateFieldState();
  statusMsg.textContent = STATUS_MSG_DEFAULT;

  recognizer.onresult = (e) => {
    
    // Removed silence timer logic

    let interimTranscript = '';
    let finalTranscriptSegment = '';

    for (let i = e.resultIndex; i < e.results.length; i++) {
      let transcript = e.results[i][0].transcript;
      transcript = transcript.replace(/[.,!?:;]$/, '').trim();
      if (e.results[i].isFinal) {
        finalTranscriptSegment += transcript + ' ';
      } else {
        interimTranscript += transcript+ ' ';
      }
    }

    // Newline handling
    if (finalTranscriptSegment) {
      NEXT_LINE_COMMANDS.forEach(cmd => {
        const regex = new RegExp(`\\b${cmd}\\b`, 'gi');
        if (regex.test(finalTranscriptSegment)) {
          finalTranscriptSegment = finalTranscriptSegment.replace(regex, '').trim();
          finalTranscriptSegment += '\n';
        }
      });
    }

    currentSpeechText += finalTranscriptSegment;

    const prefix = finalTranscripts[activeField].trim();
    const currentSessionText = (currentSpeechText + ' ' + interimTranscript).trim();
    const fullTranscript = prefix ? `${prefix} ${currentSessionText}` : currentSessionText;

    if (fullTranscript) {
      let displayTranscript = autoPunctuate(fullTranscript);
      getElements(activeField).transBar.textContent = displayTranscript;
      getElements(activeField).transBar.classList.add('live-text');
    }
  };

  recognizer.onend = () => {
    // onend will only be called now if recognizer.stop() is explicitly called (by user click or clear)
    isListening = false;
    getElements(activeField).micButton.classList.remove("listening");

    let finalQuery = (finalTranscripts[activeField] + ' ' + currentSpeechText).trim();
    finalQuery = autoPunctuate(convertWordsToNumbers(finalQuery)).trim();
    
    currentSpeechText = '';
    finalTranscripts[activeField] = finalQuery;

    updateFieldState();
    if (finalQuery) {
      statusMsg.textContent = `âœ… Transcription ended. Final text saved.`;
    } else {
      statusMsg.textContent = `Recording stopped. Tap mic to speak.`;
    }

    sendToServer(activeField, finalQuery);
  };

  recognizer.onerror = (e) => {
    isListening = false;
    getElements(activeField).micButton.classList.remove("listening");
    statusMsg.textContent = `âš ï¸ Error: ${e.error}. Try granting microphone access and refreshing.`;
    console.error("Speech Recognition Error:", e.error);
    updateFieldState();
    currentSpeechText = '';
  };

  return recognizer;
}

window.toggleRecording = function(fieldNum) {
  if (!recognizer || getElements(fieldNum).micButton.disabled) return;
  if (isListening) {
    // User clicks while listening: STOP
    recognizer.stop();
    return;
  }
  // User clicks while stopped: START
  startRecording();
};

function startRecording() {
  try {
    if (!recognizer) return;
    
    recognizer.continuous = true;
    currentSpeechText = '';
    const { micButton, transBar } = getElements(activeField);
    const previousText = finalTranscripts[activeField].trim();
    transBar.textContent = previousText ? `${previousText} Listening...` : "Listening...";
    transBar.classList.add('live-text');
    recognizer.start();
    isListening = true;
    micButton.classList.add("listening");

    // Removed silence timer logic

    statusMsg.textContent = `ðŸŽ¤ Continuous recording started. Click the mic again to stop. Say 'Next line' for a line break.`;
  } catch (e) {
    console.error("Start error:", e);
    statusMsg.textContent = `âš ï¸ Error starting mic. Check permissions or refresh.`;
  }
}

window.clearText = function(fieldNum) {
  if (isListening) {
    recognizer.stop();
  }
  finalTranscripts[fieldNum] = '';
  currentSpeechText = '';
  updateFieldState();
  statusMsg.textContent = `Text cleared.`;
  sendToServer(fieldNum, '');
};

function sendToServer(field, text) {
  // Sending to app1.py on port 5001
  const dataToSend ={
    field: field,
    text: text
  };
  fetch('/save_transcript', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json'
    },
    body: JSON.stringify(dataToSend)
  })
  .then(response => response.json())
  .then(data => {
    if (data.success) {
      console.log(`[Server] Field ${field} saved successfully.`);
    } else {
      console.error(`[Server Error] Failed to save field ${field}:`, data.message);
    }
  })
  .catch((error) => {
    console.error('[Fetch Error]: Could not reach server to save transcript.', error);
  });
  console.log(`[Simulated Server Call] Field: ${field}, Text: "${text}"`);
}

// Initialize on load
initializeSpeechRecognition();
</script>
</body>
</html>
